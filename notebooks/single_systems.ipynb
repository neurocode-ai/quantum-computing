{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "944428ef",
   "metadata": {},
   "source": [
    "$$\\newcommand{\\ket}[1]{\\left|{#1}\\right\\rangle}$$$$\\newcommand{\\bra}[1]{\\left\\langle{#1}\\right|}$$$$\\newcommand{\\braket}[2]{\\left\\langle{#1}\\middle|{#2}\\right\\rangle}$$\n",
    "# Single systems\n",
    "\n",
    "This notebook introduces the basic framework of *quantum information*, including the description of quantum states as vectors with complex number entries, measurements that allow classical information to be extracted from quantum states, and operations on quantum states that are described by unitary matrices.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de795c80",
   "metadata": {},
   "source": [
    "## 1. Classical information\n",
    "\n",
    "To describe quantum information we will begin with an overview of *classical* information. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03240d76",
   "metadata": {},
   "source": [
    "### 1.1 Classical states and probability vectors\n",
    "\n",
    "Suppose that we have a *system* that stores information. And let's assume that this system can be in one of a finite number of *classical states* at each instant. The simplest example which is at the foundation of information theory, is that of a *bit*, which is a system of classical states 0 and 1.\n",
    "\n",
    "Let us give the name $X$ to the system being considered, and let us denote $\\Sigma$ as the set of classical states of $X$. As well as the assumption that $\\Sigma$ is finite, we also have to assume that $\\Sigma$ is nonempty: it makes no sense for a system to have no states at all.\n",
    "\n",
    "For example, if $X$ is a bit, then $\\Sigma = \\{0, 1\\}$, or if $X$ is a regular die, then $\\Sigma = \\{1, 2, 3, 4, 5, 6\\}$.\n",
    "\n",
    "Often in information processing, the knowledge of $X$ is uncertain. We represent our knowledge of the classical state of $X$ by assigning probabilities to each classical state, resulting in a *probabilistic state*.\n",
    "\n",
    "For example, again assume $X$ is a bit. Based on what has happened preivously, we might believe that $X$ is in the classical state 0 three out of four times, and subsequently in the classical state 1 one out of four times. We can represent this belief by writing:\n",
    "$$Pr(X = 0) = \\frac{3}{4} \\text{   and   } Pr(X = 1) = \\frac{1}{4}$$.\n",
    "\n",
    "But a more efficient way of representing this probabilistic state is by a column vector:\n",
    "$$\\begin{pmatrix}\\frac{3}{4}\\\\\\frac{1}{4}\\end{pmatrix}$$\n",
    "\n",
    "We can represent any probabilistic state through a column vector statisfying two main properties:\n",
    "\n",
    "1. All entries of the vector are *nonnegative real numbers*.\n",
    "2. The sum of the entires is equal to 1.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e9d85df",
   "metadata": {},
   "source": [
    "### 1.2 Measuring probabilistic states\n",
    "\n",
    "Now we have to consider what happens if we were to *measure* a system when it is in a probabilistic state. By measuring a system, we mean that we look at the system and unambigiously recognize the classical state it is in. Intuitively, we can never \"see\" a system in a probabilistic state; a measurement yields exactly one of the allowed classical states.\n",
    "\n",
    "Measurements change our knowledge of a system, and therefore changes the probabilistic state that we associate with that system: if we recognize that $X$ is in the classical state $\\alpha \\in \\Sigma$, then the new probability vector representing our knowledge of $X$ becomes a vector having a $1$ in the entry corresponding to $\\alpha$ and $0$ for all other entries. This vector indicates that $X$ is in the classical state $\\alpha$ with certainty, which we know, since we just measured and recognized it.\n",
    "\n",
    "We denote the vector having a $1$ in the entry corresponding to $\\alpha$ and $0$ for all other entries by $\\ket{\\alpha}$ which is called \"ket $\\alpha$\", vectors like these are also called *standard basis vectors*.\n",
    "\n",
    "For example, if the system in question is a bit, the standard basis vectors are given by\n",
    "$$\\ket{0} = \\begin{pmatrix}1\\\\0\\end{pmatrix} \\text{  and  } \\ket{1} = \\begin{pmatrix}0\\\\1\\end{pmatrix}$$\n",
    "\n",
    "Remember that any two-dimensional column vector can be represented as a linear combination of these two vectors. For example\n",
    "$$\\begin{pmatrix}\\frac{3}{4}\\\\\\frac{1}{4}\\end{pmatrix} = \\frac{3}{4}\\ket{0} + \\frac{1}{4}\\ket{1}$$.\n",
    "\n",
    "This fact naturally generalizes to any classical state: any column vector is a linear combination over the classical states. Returning to the change of a probabilistic state uopn being measured. Suppose that we flip a fair coin, but cover up the coin before looking at it. We could then say that its probabilistic state is\n",
    "$$\\begin{pmatrix}\\frac{1}{2}\\\\\\frac{1}{2}\\end{pmatrix} = \\frac{1}{2}\\ket{\\text{ heads}} + \\frac{1}{2}\\ket{\\text{ tails}}$$.\n",
    "\n",
    "Here, the classical state $\\Sigma$ of our coin $X$ is $\\{\\text{ heads}, \\text{ tails}\\}$, we'll choose to order these states as heads first, tails second.\n",
    "$$\\ket{\\text{ heads}} = \\begin{pmatrix}1\\\\0\\end{pmatrix} \\text{   and   } \\ket{\\text{ tails}} = \\begin{pmatrix}0\\\\1\\end{pmatrix}$$\n",
    "\n",
    "If we were to uncover the coin and look at it, we would see either one of the two classical states: heads or tails. Supposing that the result were tails, we would update our description of the probabilistic state of the coin so that it becomes $\\ket{\\text{ tails}}$.\n",
    "\n",
    "One final remark concerning measurements of probabilistic states: they may describe knowledge or belief, not necessarily something actual. The state of our coin after we flip it, but before we look, is either heads or tails, and we simply do not know which until we look. Doing so does not actually change the state, but only our knowledge of it. Upon seeing that the classical state is tails, we naturally update our knowledge by assigning the vector $\\ket{\\text{ tails}}$ to the coin, but to someone else who did not see the coin when it was uncovered, the probabilisitc state remains unchanged."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdd35e86",
   "metadata": {},
   "source": [
    "### 1.3 Classical operations\n",
    "\n",
    "In this last part of the summary of classical information, we will consider the sorts of operations one might perform on a classical system.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bda53c1",
   "metadata": {},
   "source": [
    "### Deterministic operations\n",
    "\n",
    "First, there are *deterministic* operations, where each classical state $\\alpha \\in \\Sigma$ is transformed into $f(\\alpha)$ for some function $f$ of the form $f: \\Sigma \\to \\Sigma$.\n",
    "\n",
    "For example, if $\\Sigma = \\{0, 1\\}$, there are four functions of this form $f_1, f_2, f_3, \\text{ and } f_4$, which can be represented by tables of values as follows:\n",
    "\n",
    "| $\\alpha$ | $f_1$ | | $\\alpha$ | $f_2$ | | $\\alpha$ | $f_3$ | | $\\alpha$ | $f_4$ |\n",
    "|:-|:-|:-|:-|:-|:-|:-|:-|:-|:-|:-|\n",
    "| 0 | 0 | | 0 | 0 | | 0 | 1 | | 0 | 1 |\n",
    "| 1 | 0 | | 1 | 1 | | 1 | 0 | | 1 | 1 |\n",
    "\n",
    "The first and last of these functions are *constant*: $f_1(\\alpha) = 0$ and $f_4(\\alpha) = 1$, $\\forall \\alpha \\in \\Sigma$. The middle two are not constant, they are *balanced*, meaning that the two possible output values occur the same number of times as we range over the input space. The function $f_2$ is the *identity function*: $f_2(\\alpha) = \\alpha$, $\\forall \\alpha \\in \\Sigma$. And $f_3$ is the NOT-function, $f_3(0) = 1$ and $f_3(1) = 0$.\n",
    "\n",
    "The actions of deterministic operations on probabilistic states can be represented by matrix-vector multiplication. More specifically, the matrix $M$ that represent a given function $f:\\Sigma \\to \\Sigma$ is the one that satisfies\n",
    "$$M\\ket{\\alpha} = \\ket{f(\\alpha)}, \\forall \\alpha \\in \\Sigma,$$\n",
    "such a matrix always exists and is always unique.\n",
    "\n",
    "For example, the matrices $M_1, ..., M_4$ corresponding to the functions $f_1, ..., f_4$ above are as follows:\n",
    "$$M_1 = \\begin{pmatrix}1 & 1\\\\0 & 0\\end{pmatrix}, M_2 = \\begin{pmatrix}1 & 0\\\\0 & 1\\end{pmatrix}, M_3 = \\begin{pmatrix}0 & 1\\\\1 & 0\\end{pmatrix}, M_4 = \\begin{pmatrix}0 & 0\\\\1 & 1\\end{pmatrix}.$$\n",
    "\n",
    "Matrices that represent deterministic operations always have exactly one $1$ in each column, and $0$ for all other entires. A convenient way to represent matrices of these and other forms makes use of an analogous notation for row vectors to the one for column vectors discussed previously. We denote by $\\bra{\\alpha}$ the *row* vector having a $1$ in the entry corresponding to the value $\\alpha$ and $0$ for all other entires, $\\forall \\alpha \\in \\Sigma$. This vector is read as \"bra $\\alpha$\".\n",
    "\n",
    "For example, if $\\Sigma = \\{0, 1\\}$, then\n",
    "$$\\bra{0} = \\begin{pmatrix}1 & 0\\end{pmatrix} \\text{   and   } \\bra{1} = \\begin{pmatrix}0 & 1\\end{pmatrix}.$$\n",
    "\n",
    "For an arbitrary choice of classical state set $\\Sigma$, viewing row vectors and column vectors as matrices and performing the matrix multiplication $\\ket{\\beta}\\bra{\\alpha}$, one obtains a square matrix having a $1$ in the entry corresponding to the pair $(\\beta, \\alpha)$, meaning that the row of the entry corresponds to $\\beta$ and the column corresponds to $\\alpha$, and $0$ for all other entries. For example,\n",
    "$$\\ket{0}\\bra{1} = \\begin{pmatrix}0 & 1\\\\0 & 0\\end{pmatrix}.$$\n",
    "\n",
    "Using this notation, for any function $f:\\Sigma \\to \\Sigma$, we may express the matrix $M$ corresponding to the function $f$ as \n",
    "$$M = \\sum_{\\alpha \\in \\Sigma}\\ket{f(\\alpha)}\\bra{\\alpha}.$$\n",
    "\n",
    "Now, if we again think about vectors as matrices, but this time consider the multiplication $\\bra{\\alpha}\\ket{\\beta}$, then we obtain a $1\\times1$ matrix, which we can think about as a scalar. For the sake of tidiness, we write this product as $\\braket{\\alpha}{\\beta}$. This product satisfies the following simple formula:\n",
    "$$\\braket{\\alpha}{\\beta} = \\begin{cases}1 & \\alpha=\\beta\\\\0 & \\alpha\\neq\\beta\\end{cases}.$$\n",
    "\n",
    "Using this observation, together with the knowledge that matrix multiplication is associative and linear, we obtain\n",
    "$$M\\ket{\\beta} = \\biggl( \\sum_{\\alpha \\in \\Sigma}\\ket{f(\\alpha)}\\bra{\\alpha}\\biggr)\\ket{\\beta} = \\sum_{\\alpha \\in \\Sigma}\\ket{f(\\alpha)}\\braket{\\alpha}{\\beta} = \\ket{f(\\beta)}, \\forall \\beta \\in \\Sigma,$$\n",
    "which is exactly what we require of $M$.\n",
    "\n",
    "As we also will discuss later, $\\braket{\\alpha}{\\beta}$ may be seen as the *inner product* between the vectors $\\ket{\\alpha}$ and $\\ket{\\beta}$. The \"bracket\"/braket notation and terminology is due to *Paul Dirac*, and for this reason is also known as the *Dirac notation*.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ef41a39",
   "metadata": {},
   "source": [
    "### Probabilistic operations and stochastic matrices\n",
    "\n",
    "In addition to deterministic operations, we also have *probabilistic operations*.\n",
    "\n",
    "For example, consider an operation on a bit where, if the classical state of the bit is $0$, it is left alone, and if the classical state of the bit is $1$, it is flipped to $0$ with probability $\\frac{1}{2}$. This operation is represented by the matrix\n",
    "$$\\begin{pmatrix}1 & \\frac{1}{2}\\\\0 & \\frac{1}{2}\\end{pmatrix}.$$\n",
    "\n",
    "For an arbitrary choice of classical state set, we can describe the set of all probabilistic operations in mathematical terms as those that are represented by *stochastic* matrices, which are matrices satisfying these two properties:\n",
    "\n",
    "1. All entries are nonnegative real numbers.\n",
    "2. The entires in every column sum to 1.\n",
    "\n",
    "Equivalently, stochastic matrices are matrices whose columns all form probability vectors.\n",
    "\n",
    "We can think about probabilistic operations at an intuitive level as ones where randomness might somehow be used or introduced during the operation, just like in the example above. With respect to the stochastic matrix description of a probabilistic operation, each column can be viewed as a vector representation of the probabilistic state that is generated given whatever classical state input corresponds to that column. \n",
    "\n",
    "We can also think about stochastic matrices as being exactly those matrices that always map probability vectors to probability vectors. That is, stochastic matrices always map probability vectors to probability vectors, and any matrix that always maps probability vectors to probability vectors must be a stochastic matrix.\n",
    "\n",
    "Finally, another way to think about probabilistic operations are that they are random choices of deterministic operations. For instance, we can think about the operation in the example above as applying either the identity function of the constant $0$ function, each with probability $\\frac{1}{2}$. This is consistent with the equation\n",
    "$$\\begin{pmatrix}1 & \\frac{1}{2}\\\\0 & \\frac{1}{2}\\end{pmatrix} = \\frac{1}{2}\\begin{pmatrix}1 & 0\\\\0 & 1\\end{pmatrix} + \\frac{1}{2}\\begin{pmatrix}1 & 1\\\\0 & 0\\end{pmatrix}.$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb12a81b",
   "metadata": {},
   "source": [
    "### Compositions of probabilistic operations\n",
    "\n",
    "Suppose that $X$ is a system having a classical state $\\Sigma$, and $M_1, ..., M_n$ are stochastic matrices representing probabilistic operations on the system $X$.\n",
    "\n",
    "If the first operation $M_1$ is applied to the probabilistic state represented by a probability vector $u$, the resulting probabilistic state is represented by the vector $M_1u$. If we then apply the second probabilistic operation $M_2$ to the new probability vector, we obtain the probability vector\n",
    "$$M_2(M_1u) = (M_2M_1)u.$$\n",
    "\n",
    "The equality follows from the fact that matrix multiplication is an *associative* operation. Thus, the probabilistic operation obtained by *composing* the first and second probabilistic operations, where we first apply $M_1$ and then apply $M_2$, is represented by the matrix $M_2M_1$, which also is stochastic.\n",
    "\n",
    "Note that the ordering is important here: although matrix multiplication is associative, it is not a *commutative* operation in general. For example, if we have\n",
    "$$M_1 = \\begin{pmatrix}1 & 1\\\\0 & 0\\end{pmatrix} \\text{   and   } M_2 = \\begin{pmatrix}0 & 1\\\\1 & 0\\end{pmatrix}$$\n",
    "then\n",
    "$$M_2M_1 = \\begin{pmatrix}0 & 0\\\\1 & 1\\end{pmatrix} \\text{   and   } M_1M_2 = \\begin{pmatrix}1 & 1\\\\0 & 0\\end{pmatrix}$$.\n",
    "\n",
    "That is, the order in which probabilistic operations are composed matters: changing the order in which operations are applied in a composition can change the resulting operation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6b9e675",
   "metadata": {},
   "source": [
    "## 2. Quantum information\n",
    "\n",
    "Now we move on to quantum information, where we make a different choice for the type of vector that represents a state - in this case a *quantum state* - of the system being considered.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cba899d",
   "metadata": {},
   "source": [
    "### 2.1 Quantum state vectors\n",
    "\n",
    "A *quantum state* of a system is represented by a column vector, similar to probabilistic states. As before, the indices of the vector label the classical states of the system. Vectors representing quantum states are characterized by the following two properties:\n",
    "\n",
    "1. The entries of the quantum state vector are *complex numbers*.\n",
    "2. The sum of the *absolute values squared* of the entries of a quantum state vector must equal $1$.\n",
    "\n",
    "This, vectors representing quantum states need not have nonnegative real number entries, and it is the sum of the absolute values squared of the entries that must equal $1$. Simple as these changes are, they give rise to all the differences between quantum and classical information.\n",
    "\n",
    "The *Euclidean norm* of a column vector\n",
    "$$v = \\begin{pmatrix}\\alpha_1\\\\\\vdots\\\\\\alpha_n\\end{pmatrix}$$\n",
    "is denoted and defined as follows:\n",
    "$$||v|| = \\sqrt{\\sum_{k=1}^n|\\alpha_k|^2}.$$\n",
    "\n",
    "The condition that the sum of the absolute values squared of a quantum state vector equals $1$ is therefore equivalent to that vector having Euclidean norm equal to $1$. That is, quantum state vectors are *unit vectors* with respect to the Euclidean norm.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b98433d6",
   "metadata": {},
   "source": [
    "### Examples of qubit states\n",
    "\n",
    "The term *qubit* refers to a quantum system whose classical state set is $\\Sigma = \\{0, 1\\}$. These are examples of quantum states of a qubit:\n",
    "$$\\begin{pmatrix}1\\\\0\\end{pmatrix}=\\ket{0} \\text{   and   } \\begin{pmatrix}0\\\\1\\end{pmatrix} = \\ket{1},$$\n",
    "$$\\begin{pmatrix}\\frac{1}{\\sqrt{2}}\\\\\\frac{1}{\\sqrt{2}}\\end{pmatrix} = \\frac{1}{\\sqrt{2}}\\ket{0} + \\frac{1}{\\sqrt{2}}\\ket{1},$$\n",
    "and\n",
    "$$\\begin{pmatrix}\\frac{1 + 2i}{3}\\\\-\\frac{2}{\\sqrt{3}}\\end{pmatrix} = \\frac{1 + 2i}{\\sqrt{3}}\\ket{0} - \\frac{2}{\\sqrt{3}}\\ket{1}.$$\n",
    "\n",
    "Similar to the classical setting, we associate the quantum state vectors $\\ket{0}$ and $\\ket{1}$ with a qubit being in the classical state $0$ or $1$, respectively, with certainty.\n",
    "\n",
    "For the last two examples, we have complex number entires, computing the sum of the absolute value squared of the entires yields\n",
    "$$|\\frac{1}{\\sqrt{2}}|^2 + |\\frac{1}{\\sqrt{2}}|^2 = \\frac{1}{2} + \\frac{1}{2} = 1$$\n",
    "and\n",
    "$$|\\frac{1 + 2i}{3}|^2 + |-\\frac{2}{3}|^2 = \\frac{(1 + 2i)(1 - 2i)}{9} + \\frac{4}{9} = \\frac{5}{9} + \\frac{4}{9} = 1.$$\n",
    "\n",
    "These are therefore valid quantum state vectors. Note that they are linear combinations of the states $\\ket{0}$ and $\\ket{1}$. We often say that these states are *superpositions* of the $0$ and $1$ states. Within the context of quantum systems, \"superposition\" and \"linear combination\" are essentially synonymous.\n",
    "\n",
    "It is quite common to use notation such as $\\ket{\\psi}$ whose indices correspond to some classical state set $\\Sigma$, and if $\\alpha \\in \\Sigma$ is an element of this classical set, then the (matrix) product $\\braket{\\alpha}{\\psi}$ is equal to the entry of the vector $\\ket{psi}$ whose index corresponds to the value $\\alpha$.\n",
    "\n",
    "For example, if $\\Sigma = \\{0, 1\\}$ and\n",
    "$$\\ket{\\psi} = \\frac{1 + 2i}{3}\\ket{0} - \\frac{2}{3}\\ket{1} = \\begin{pmatrix}\\frac{1 + 2i}{3}\\\\-\\frac{2}{3}\\end{pmatrix},$$\n",
    "then\n",
    "$$\\braket{0}{\\psi} = \\frac{1 + 2i}{3} \\text{   and   } \\braket{1}{\\psi} = -\\frac{2}{3}.$$\n",
    "\n",
    "It must be understood when using this notation that $\\bra{\\psi}$ refers to the row vector obtained when taking the *conjugate-transpose* of the column vector $\\ket{\\psi}$, where (in addition to transposing the vector from a column vector to a row vector) each entry is replaced by its complex conjugate.\n",
    "\n",
    "For example, if $\\ket{\\psi}$ is the vector defined above, then\n",
    "$$\\bra{\\psi} = \\frac{1 - 2i}{3}\\bra{0} - \\frac{2}{3}\\bra{1} = \\begin{pmatrix}\\frac{1 - 2i}{3} & -\\frac{2}{3}\\end{pmatrix}.$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c2ce76d",
   "metadata": {},
   "source": [
    "### Quantum states of other systems\n",
    "\n",
    "We can consider quantum states of systems having arbitrary classical state sets.\n",
    "\n",
    "For example, here is a quantum state vector for an electrical fan switch:\n",
    "$$\\begin{pmatrix}\\frac{1}{2}\\\\0\\\\-\\frac{i}{2}\\\\\\frac{1}{\\sqrt{2}}\\end{pmatrix} = \\frac{1}{2}\\ket{\\text{ high }} -\\frac{i}{2}\\ket{\\text{ low }} + \\frac{1}{\\sqrt{2}}\\ket{\\text{ off }}$$\n",
    "\n",
    "The assumption here is that the classical states are ordered as *high*, *medium*, *low*, *off*. There may be no particular reason why one would want to consider a quantum state of an electrical switch, but it is possible in principle.\n",
    "\n",
    "Here is another example, this time a quantum decimal digit whose classical states are $\\Sigma = \\{0, 1, ..., 9\\}$:\n",
    "$$\\frac{1}{\\sqrt{385}}\\begin{pmatrix}1\\\\2\\\\3\\\\4\\\\5\\\\6\\\\7\\\\8\\\\9\\\\10\\end{pmatrix} = \\frac{1}{\\sqrt{385}}\\sum_{k=0}^9(k+1)\\ket{k}.$$\n",
    "\n",
    "This example illustrates the convenience of writing state vectors using the Dirac notation. For this particular example, the column vector representation is merely cumbersome - but if there were significantly more classical states it would become unusable. The Dirac notation, in contrast, supports precise descriptions of large and complicated vectors in compact form. \n",
    "\n",
    "The Dirac notation allows for the expression of vectors where different aspects of the vectors are *indeterminate*. For example, for an arbitrary classical state set $\\Sigma$, we can consider the quantum state vector\n",
    "$$\\frac{1}{\\sqrt{|\\Sigma|}}\\sum_{\\alpha \\in \\Sigma} \\ket{\\alpha},$$\n",
    "\n",
    "which is a uniform superposition over the classical states in $\\Sigma$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dac9e35",
   "metadata": {},
   "source": [
    "### 2.2 Measuring quantum states\n",
    "\n",
    "Next let us consider what happens when a quantum state is *measured*, focusing on a simple type of measurement known as a *standard basis measurement*.\n",
    "\n",
    "Similar to the probabilistic setting, when a system in a quantum state is measured, the observer performing the measurement won't see a quantum state vector, but rather some classical state. In this sense, measurements act as the interface between quantum and classical information, through which classical information is extracted from quantum states.\n",
    "\n",
    "The rule is as follows: if a quantum state is measured, each classical state of the system results with probability equal to the absolute value squared of the entry in the quantum state vector corresponding to that classical state. This is known as the *Born rule* in quantum mechanics.\n",
    "\n",
    "For example, measuring the plus state\n",
    "$$\\ket{ +} = \\frac{1}{\\sqrt{2}}\\ket{0} + \\frac{1}{\\sqrt{2}}\\ket{1}$$\n",
    "results in the two possible outcomes, $0$ and $1$, with probabilities as follows.\n",
    "$$Pr(\\text{result is }0) = |\\braket{0}{+}|^2 = |\\frac{1}{\\sqrt{2}}|^2 = \\frac{1}{2}$$\n",
    "$$Pr(\\text{result is }1) = |\\braket{1}{+}|^2 = |\\frac{1}{\\sqrt{2}}|^2 = \\frac{1}{2}$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd8ce5a7",
   "metadata": {},
   "source": [
    "### 2.3 Unitary operations\n",
    "\n",
    "Thus far, it may not be evident why quantum information is fundamentally different from classical information. That is, when a quantum state is measured, the probability to obtain each classical state is given by the absolute value squared of the corresponding vector entry - so why not simply record these probabilities in a probability vector?\n",
    "\n",
    "The answer, at least in part, is that the set of allowable *operations* that can be performed on a quantum state is different than it is for classical information. Similar to the probabilistic setting, operation on quantum states are linear mappings - but rather than being represented by stochastic matrices as in the classical case, operations on quantum state vectors"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
